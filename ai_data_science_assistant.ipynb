{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cb18baad",
   "metadata": {},
   "source": [
    "# AI Data Science Assistant Chatbot \n",
    "\n",
    "This project is a local, cost-free data science assistant built with LangChain, Pandas, and the LLaMA 3 model via Ollama. \n",
    "Users can upload CSV files and ask natural language questions to extract insights from structured data â€” no code or API keys are required. \n",
    "This project showcases Retrieval-Augmented Generation (RAG) and tool-augmented LLMs to simulate a conversational data analyst, \n",
    "capable of answering statistical, comparative, and exploratory questions over real-world datasets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8aa6b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure to have:\n",
    "# 1. Python installed\n",
    "# 2. Ollama installed from https://ollama.com\n",
    "# 3. Run this in a Jupyter notebook OR as a script\n",
    "\n",
    "# Uncomment below if needed \n",
    "# !pip install pandas langchain ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a76176e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from langchain.agents import create_pandas_dataframe_agent\n",
    "from langchain_community.llms import Ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d99497",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Load your CSV dataset\n",
    "# Replace this with your actual file path\n",
    "csv_path = \"sample.csv\"  # Example: sample CSV provided below\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "# Preview the data\n",
    "print(\"Dataset preview:\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e79b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Initialize the local LLaMA 3 model via Ollama\n",
    "# Make sure 'ollama run llama3' is running in a separate terminal window\n",
    "llm = Ollama(model=\"llama3\")\n",
    "\n",
    "# Step 3: Create the LangChain agent to interface with your DataFrame\n",
    "agent = create_pandas_dataframe_agent(llm, df, verbose=True)\n",
    "\n",
    "# Step 4: Ask a question about your data\n",
    "question = \"Which country has the highest average sales?\"\n",
    "\n",
    "print(\"\\nQuestion:\")\n",
    "print(question)\n",
    "print(\"\\nAnswer:\")\n",
    "response = agent.run(question)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a152b3b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Ask more questions\n",
    "# Example: \n",
    "response = agent.run(\"Show me total revenue for all countries\")\n",
    "print(\"\\nAnswer:\")\n",
    "print(response)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
